{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-09T19:08:29.539208Z","iopub.execute_input":"2024-03-09T19:08:29.540204Z","iopub.status.idle":"2024-03-09T19:08:30.526370Z","shell.execute_reply.started":"2024-03-09T19:08:29.540146Z","shell.execute_reply":"2024-03-09T19:08:30.525369Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv\n/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_label(arg):\n    if arg=='Positive':\n        return 0\n    elif arg=='Neutral':\n        return 1\n    elif arg=='Negative':\n        return 2","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:13.015127Z","iopub.execute_input":"2024-03-09T19:28:13.015488Z","iopub.status.idle":"2024-03-09T19:28:13.020311Z","shell.execute_reply.started":"2024-03-09T19:28:13.015460Z","shell.execute_reply":"2024-03-09T19:28:13.019395Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\n# Load your CSV dataset\ndf = pd.read_csv(\"/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\")\ndf.columns = ['id','border','label','text']\ndf = df[['text','label']]\ndf = df.dropna().reset_index(drop=True)\ndf = df[(df.label=='Positive')|(df.label=='Neutral')|(df.label=='Negative')]\ndf['label'] = df.label.apply(lambda x: get_label(x))\ndf['label'] = df['label'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:13.306317Z","iopub.execute_input":"2024-03-09T19:28:13.306648Z","iopub.status.idle":"2024-03-09T19:28:13.640577Z","shell.execute_reply.started":"2024-03-09T19:28:13.306623Z","shell.execute_reply":"2024-03-09T19:28:13.639683Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  I am coming to the borders and I will kill you...      0\n1  im getting on borderlands and i will kill you ...      0\n2  im coming on borderlands and i will murder you...      0\n3  im getting on borderlands 2 and i will murder ...      0\n4  im getting into borderlands and i can murder y...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im getting into borderlands and i can murder y...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import math\ndf_test = df[(math.floor(df.shape[0]*0.7)):]\ndf = df[0:(math.floor(df.shape[0]*0.7))]\n\nprint('train:', format(df.shape[0],','))\nprint('test:', format(df_test.shape[0],','))","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:16.795907Z","iopub.execute_input":"2024-03-09T19:28:16.796732Z","iopub.status.idle":"2024-03-09T19:28:16.803014Z","shell.execute_reply.started":"2024-03-09T19:28:16.796698Z","shell.execute_reply":"2024-03-09T19:28:16.802095Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train: 42,784\ntest: 18,336\n","output_type":"stream"}]},{"cell_type":"code","source":"df.label.unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:17.734135Z","iopub.execute_input":"2024-03-09T19:28:17.734789Z","iopub.status.idle":"2024-03-09T19:28:17.743230Z","shell.execute_reply.started":"2024-03-09T19:28:17.734759Z","shell.execute_reply":"2024-03-09T19:28:17.742320Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 2])"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch import optim\n\nprint(torch.cuda.is_available())\nprint(torch.cuda.current_device())","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:18.388700Z","iopub.execute_input":"2024-03-09T19:28:18.389361Z","iopub.status.idle":"2024-03-09T19:28:21.346770Z","shell.execute_reply.started":"2024-03-09T19:28:18.389324Z","shell.execute_reply":"2024-03-09T19:28:21.345798Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"True\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\nclass MyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenize input text\n        tokenized_input = self.tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n\n        # Return a dictionary with the tokenized input and label\n        return {\n            'input_ids': tokenized_input['input_ids'].squeeze(),\n            'attention_mask': tokenized_input['attention_mask'].squeeze(),\n            'token_type_ids': tokenized_input['token_type_ids'].squeeze(),\n            'labels': torch.tensor(label)\n        }\n\n# Example usage\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n# Move the model to the GPU\nmodel.to('cuda')\n\n# Create an instance of the custom dataset\ntexts = df['text'].tolist()\nlabels = df['label'].tolist()\nmy_dataset = MyDataset(texts, labels, tokenizer)\n\ndef my_collate_fn(batch):\n    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True)\n    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True)\n    token_type_ids = pad_sequence([item['token_type_ids'] for item in batch], batch_first=True)\n    labels = torch.stack([item['labels'] for item in batch])\n    \n    return {\n        'input_ids': input_ids.to('cuda'),\n        'attention_mask': attention_mask.to('cuda'),\n        'token_type_ids': token_type_ids.to('cuda'),\n        'labels': torch.tensor(labels).to('cuda')\n    }\n\n# Initialize optimizer (you need to define it somewhere in your code)\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\n# Create a DataLoader using the custom dataset with collate_fn argument\ntrain_data_loader = DataLoader(my_dataset, batch_size=32, shuffle=True, collate_fn=my_collate_fn)\n\n# Example fine-tuning loop (simplified)\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    for batch in train_data_loader:\n        inputs = {\n            'input_ids': batch['input_ids'],\n            'attention_mask': batch['attention_mask'],\n            'token_type_ids': batch['token_type_ids'],\n            'labels': batch['labels']\n        }\n        # Move the data to the GPU\n        for key in inputs:\n            inputs[key] = inputs[key].to('cuda')\n        optimizer.zero_grad()\n        outputs = model(**inputs)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:28:21.348913Z","iopub.execute_input":"2024-03-09T19:28:21.349793Z","iopub.status.idle":"2024-03-09T19:45:57.257574Z","shell.execute_reply.started":"2024-03-09T19:28:21.349754Z","shell.execute_reply":"2024-03-09T19:45:57.256657Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e508403cbfe8420481ffd3ad1ecec55f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7d84a475ef940e28b85ab5397eaa2bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f94317376ee340dfaed7d97c3faf3e28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb16948af43c4003b1e132ea9dd19486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39143077bb2b4ffaa482abf97a35a07e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_34/2472744794.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  'labels': torch.tensor(labels).to('cuda')\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_label(arg):\n    if arg==0:\n        return 'Positive'\n    elif arg==1:\n        return 'Neutral'\n    elif arg==2:\n        return 'Negative'","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:45:57.258743Z","iopub.execute_input":"2024-03-09T19:45:57.259293Z","iopub.status.idle":"2024-03-09T19:45:57.263986Z","shell.execute_reply.started":"2024-03-09T19:45:57.259266Z","shell.execute_reply":"2024-03-09T19:45:57.262964Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_pred(arg):\n    tokenized_inputs = tokenizer(arg, padding=True, truncation=True, return_tensors='pt').to('cuda')\n\n    with torch.no_grad():\n        outputs = model(**tokenized_inputs)\n\n    logits = outputs.logits\n\n    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n    predicted_class = torch.argmax(probabilities, dim=-1).item()\n\n    #predicted_labels = get_label(predicted_class)\n    predicted_labels = predicted_class\n    return predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:56:44.080507Z","iopub.execute_input":"2024-03-09T19:56:44.081190Z","iopub.status.idle":"2024-03-09T19:56:44.087274Z","shell.execute_reply.started":"2024-03-09T19:56:44.081157Z","shell.execute_reply":"2024-03-09T19:56:44.086295Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:59:50.881295Z","iopub.execute_input":"2024-03-09T19:59:50.881948Z","iopub.status.idle":"2024-03-09T19:59:50.886736Z","shell.execute_reply.started":"2024-03-09T19:59:50.881914Z","shell.execute_reply":"2024-03-09T19:59:50.885750Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df['pred_label'] = df['text'].progress_apply(lambda x: get_pred(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T19:59:51.557901Z","iopub.execute_input":"2024-03-09T19:59:51.558757Z","iopub.status.idle":"2024-03-09T20:07:09.379035Z","shell.execute_reply.started":"2024-03-09T19:59:51.558717Z","shell.execute_reply":"2024-03-09T20:07:09.378101Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/42784 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64dfdcb17386483aad2bea47a27909eb"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                text  label  pred_label\n0  I am coming to the borders and I will kill you...      0           0\n1  im getting on borderlands and i will kill you ...      0           0\n2  im coming on borderlands and i will murder you...      0           0\n3  im getting on borderlands 2 and i will murder ...      0           0\n4  im getting into borderlands and i can murder y...      0           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am coming to the borders and I will kill you...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im getting on borderlands and i will kill you ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>im getting on borderlands 2 and i will murder ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im getting into borderlands and i can murder y...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"correct_predictions = (df['label'] == df['pred_label']).sum()\ntotal_predictions = len(df)\naccuracy = correct_predictions / total_predictions\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:07:09.380987Z","iopub.execute_input":"2024-03-09T20:07:09.381618Z","iopub.status.idle":"2024-03-09T20:07:09.387743Z","shell.execute_reply.started":"2024-03-09T20:07:09.381583Z","shell.execute_reply":"2024-03-09T20:07:09.386860Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Accuracy: 97.99%\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test['pred_label'] = df_test.text.progress_apply(lambda x: get_pred(x))\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:07:09.388942Z","iopub.execute_input":"2024-03-09T20:07:09.389292Z","iopub.status.idle":"2024-03-09T20:10:19.010919Z","shell.execute_reply.started":"2024-03-09T20:07:09.389261Z","shell.execute_reply":"2024-03-09T20:10:19.009961Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/18336 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7984bc8696431488254010243ff02c"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                    text  label  pred_label\n52493  @ RockstarGames does not work red dead redeemm...      2           2\n52494  @RockstarGames not working red dead redemption...      2           2\n52495  @RockstarGames not on working red dead redempt...      2           2\n52496  @RockstarGames not complete red dead redemptio...      2           2\n52497  Skinned this in red dead redemption 2 yesterda...      1           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>52493</th>\n      <td>@ RockstarGames does not work red dead redeemm...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>52494</th>\n      <td>@RockstarGames not working red dead redemption...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>52495</th>\n      <td>@RockstarGames not on working red dead redempt...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>52496</th>\n      <td>@RockstarGames not complete red dead redemptio...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>52497</th>\n      <td>Skinned this in red dead redemption 2 yesterda...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"correct_predictions = (df_test['label'] == df_test['pred_label']).sum()\ntotal_predictions = len(df_test)\naccuracy = correct_predictions / total_predictions\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-09T20:10:19.013120Z","iopub.execute_input":"2024-03-09T20:10:19.013488Z","iopub.status.idle":"2024-03-09T20:10:19.019992Z","shell.execute_reply.started":"2024-03-09T20:10:19.013456Z","shell.execute_reply":"2024-03-09T20:10:19.019051Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy: 66.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}